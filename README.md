# Gradient Descent: Insights into Behavior and Optimization Challenges

## Project Overview

This project explores the **practical behavior of Gradient Descent** through the lens of **Mean Squared Error (MSE)** minimization in simple linear regression.

Beyond the standard textbook implementation, this notebook investigates:

- How the **initial values** of coefficients affect convergence
- The impact of **learning rate selection** on optimization efficiency
- **Visualization of the MSE surface** to illustrate optimization paths
- Common pitfalls such as **slow convergence**, **divergence**, and **local minima**

The goal is to **diagnose and understand the practical limitations** of gradient-based optimization methods â€” a valuable perspective for both data science and machine learning engineering tasks.